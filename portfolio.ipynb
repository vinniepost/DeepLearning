{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Deeplearning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theorie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tijdens deze les hebben we een introductie van Deep Learning gekregen. Ik was hier hellaas niet bij wegens persoonlijke redenen (gewettigd). Ik heb de slides thuis bekeken en heb volgende dingen \"bijgeleerd\"\n",
    "\n",
    "1. De geschiedenis/het verleden van AI (van minder belang)\n",
    "2. De basis van neurale netwerken bestaat uit een aantal zaken. Van functies van neuronen tot activatie funties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tijdens dit labo hebben we een klein en simpel neuraal netwerk moeten bouwen. Dit ging over het algemeen heel vlot.\n",
    "De enige moeilijkheid die ik ondervond was het instaleren van tensorflow zodat die de gpu van mijn pc thuis kon gebruiken.\n",
    "Het grootste deel van de taak kwam overeen met dingen die we in het vorig semester ook gezien hebben.\n",
    "De Iris dataset van sklearn inladen gebeurd via een functie die in sklearn zit. We splitsen deze data op in zijn X (input) en y (labels) variabelen. We gebruiken deze dan om ze in de train_test_split functie van sklearn te steken om een train en test set te creeren, Ik heb hier gekozen om een testsize van 30% te nemen en een randomstate van 42 te gebruiken. De split van 70/30 is een redelijk algemene keuze en standaard. De randomstate is om er voor te zorgen dat de data die in het model komt altijd dezelfde data zal zijn.\n",
    "Vervolgens gebruik ik de standard scaler van sklearn om de data die ik in het model wil steken te scalen naar kleindere waarden. Deze scaler moet worden gefit en kan dan gebruikt worden om de X variabelen te transformeren.\n",
    "\n",
    "Nu begin ik aan mijn model. Dit doen we door uit de tensorflow de keras object te nemem en er een sequential object mee te maken. Hier steken we verschillende lagen in die het model dan zal bevatten. De lagen die ik nu heb zijn:\n",
    "1. de input layer: een Dense layer met de relu activatie functie en de vorm van een de X_train data\n",
    "2. Een hidden layer: Dense layer met de relu activatie functie\n",
    "3. Een dropout layer: Om overfitting tegen te gaan\n",
    "4. een output layer: Een uitput layer met de groote als het aantal labels die we hebben.\n",
    "Vervolgens compile we het model. we trainen het"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
